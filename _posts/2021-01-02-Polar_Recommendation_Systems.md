---

layout: post
title: Polarity in Recommendation Systems

---
##### I believe that the importance of designing ethical systems and building laws and regulations around data is understated. 

Okay, big thoughts. Today I'm going to touch on polarity in recommendation systems and how this is related to the statement I made above.

These thoughts all came about recently when I looked up a product on Amazon. I don't remember what it is, but what happened was extremely _deja vu_: I look up a lap desk to read on my computer in bed, think _ehhh_, go to Amazon's homepage, and _every single one_ of the recommended items are a lap desk but by a different ripoff brand. I'm sure you've had a similar experience as well. This, and a lot of our online experience, is partially the result of some recommendation system. And while this is great if you want to compare a ton of different options of lap desks, it's bad if what you really needed all along, was a reading tablet. 

Although in this case, there's no harm done if I get the lap desk instead of the reading tablet, the generalized case can demonstrate the theoretical importance better. What if Michael Phelps had never met a swimmer, never even seen a pool, nay, never even heard or *thought* of a pool? The simple answer is, it would be impossible for him to have become a swimmer, and the world would be devoid of our greatest swimmer ever. (Okay, another drastic and sort of irrelevant example.) I hope this at least can expose you to the idea that exposure is vital for discovery, both for personal and retail purposes.

Modern recommendation systems are designed to match users to their likes, and recommend items that they think the user will like. In the Amazon example, this translates to recommending a ton of the same item by different high-rated brands in the moments after I have just searched for that item. However, this influence is felt everywhere on the internet. Search engines such as Google, which are central to the common internet experience, also has its own recommendation systems. This means that so many services provided on the internet, also including social media, will try to cater to what it _thinks_ you like. If you like something, these systems will keep feeding that to you, in an attempt to maximize your liking of this product with a future product. 

Eli Pariser has termed this phenomenon "filter bubbles," in which our online experience and online information universe is constrained to what recommendation systems think we will like. They fundamentally change the information we encounter, and therefore our ideas. My sister likes to talk about things that are trending, only, every time its something that none of my family has heard of. And the same can be said for myself. Following the NBA is a large part of my internet consumption, and therefore I'm constanty surrounded in information related to it, think that its always the most trending thing on the planet, and likely overestimate its influence (I constantly wonder how the NFL is still more popular than the NBA, which it still overwhelmingly is).

While innocuous within my questioning of sports league dominance, this phenomenon has been extremely dangerous within political and social media contexts. Liking a post bashing Trump coincidentally is followed by more anti-Trump news in your feed, and vice versa. The hyperpolarization of political views in social media has gotten really bad in the last couple of years, with now a famous and likely growing divide between the Liberal Mainstream Media (like CNN and co.) and Conservative News (like OANN and recently Parler).

I try my best not to hate in my life. But if there is something I truly, truly abhor, it is when people *refuse* to see the other side, and clash with fostered hate. Social media has deepened this divide by allowing and even encouraging people to live within their own ideological bubble, without unbiased exposure to other views and peoples. While one would think that within a vacuum, the systems driving social media would allow ideas to flow better globally and we would see _more_ exposure and _less_ polarisation, the reality has manifested to become the opposite. 

While the example with Amazon makes the problem feel trivial, the recommendation systems that drive our online experience are at their core, social engineering, and we as a society, really need to work together to understand the technological requirements and social implications of the data systems that we work with, if we want to make sure our entire life is not just a socially engineered existence.

[Read](https://ir.library.louisville.edu/cgi/viewcontent.cgi?article=3835&context=etd) [more](https://fs.blog/2017/07/filter-bubbles/)

See you by the fire.

M




